{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify connection to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = 'https://windfarmer.dnv.com/api/v2/'\n",
    "auth_token = os.environ['WINDFARMER_ACCESS_KEY']\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {auth_token}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "response = requests.get(api_url + 'Status', headers = headers)\n",
    "print(f'Response from Status: {response.status_code}')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Part 1** - generating a demo batch of API inputs [OPTIONAL, skip if you have generated the batch otherwise] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine we are asked to remove three turbines from a layout in the most energy efficient way. We'll do that by identifying the worst 10 turbines in the layout and later evaulating the yield of a batch of alternative layouts, each created by removing 3 different turbines from the set of 10 worst producing locations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial calculation to get a feel where the most heavily waked zones are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input json for The Bowl\n",
    "with open('../../../DemoData/TheBowl/TheBowl.json', 'r') as f:\n",
    "    json_string = f.read()\n",
    "    input_data = json.loads(json_string)\n",
    "    \n",
    "start = time.time()\n",
    "response = requests.post(\n",
    "    api_url + 'AnnualEnergyProduction', \n",
    "    headers=headers,\n",
    "    json = input_data)\n",
    "    \n",
    "print(f'Response {response.status_code} - {response.reason} in {time.time() - start:.2f}s')\n",
    "# Print the error detail if we haven't receieved a 200 OK response\n",
    "if response.status_code != 200:\n",
    "    print(json.loads(response.content)['detail'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identifting the worst 10 turbines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = json.loads(response.content)\n",
    "yields = [x['fullAnnualYield_MWh_per_year'] for x in result['windFarmAepOutputs'][0]['turbineResults']]\n",
    "labels = [x['turbineName'] for x in result['windFarmAepOutputs'][0]['turbineResults']]\n",
    "yields_df = pd.DataFrame.from_dict({k:v for k,v in zip(labels, yields)}, orient='index', columns=['Yield (MWh/year)'])\n",
    "yields_df.sort_values(by='Yield (MWh/year)', ascending=True, inplace=True)\n",
    "worst_10_turbines = list(yields_df.iloc[:10].index)\n",
    "print(worst_10_turbines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generating all the possible combinations of removing two out of ten candidate turbines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_removal_alternatives = list(combinations(worst_10_turbines, 3))\n",
    "print(turbine_removal_alternatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate API inputs for each alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alternative in turbine_removal_alternatives:\n",
    "    temp_json = deepcopy(input_data)\n",
    "    for turbine in input_data[\"windFarms\"][0][\"turbines\"]:\n",
    "        if turbine[\"name\"] in alternative:\n",
    "            temp_json[\"windFarms\"][0][\"turbines\"].remove(turbine)\n",
    "    if not os.path.exists('./InputBatch'):\n",
    "        os.makedirs('./InputBatch')\n",
    "    with open('./InputBatch/{0}.json'.format('_'.join(alternative)), 'w') as f:\n",
    "        f.write(json.dumps(temp_json, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Part 2** - batch processing [if you're using this for API inputs generated outside of the script, put them in a folder `InputBatch`, next to the script]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Define user inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the desired model combination\n",
    "WAKE_MODEL_CHOICE = \"EddyViscosity\" # EddyViscosity/ModifiedPark/TurbOPark/CFDML\n",
    "BLOCKAGE_MODEL_CHOICE = \"BEET\" # BEET/CFDML\n",
    "CALCULATE_EFFICIENCIES = True #True/False \n",
    "  \n",
    "# specify the path to the input json files\n",
    "PATH_TO_INPUTS = './InputBatch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the part responsible for model settings in the input jsons contained in the `./InputBatch` directory will get overwritten by the settings specified in the code cell above  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below dictionaries contain various settings, of which we make a selection for the particular run  (inside set_model_settings)\n",
    "lwf_paramters = { # LWF's default offshore settings\n",
    "                    \"baseRoughnessZ01\": 0.0002,\n",
    "                    \"increasedRoughnessZ02\": 0.0192,\n",
    "                    \"geometricWidthDiameters\": 1.0,\n",
    "                    \"recoveryStartDiameters\": 120.0,\n",
    "                    \"fiftyPercentRecoveryDiameters\": 40.0\n",
    "                }\n",
    "wake_models = {\"EddyViscosity\": {\"model_key\":\"eddyViscosity\", \"model_settings\":{\"useLargeWindFarmModel\": True, \"largeWindFarmCorrectionParameters\": lwf_paramters}},\n",
    "               \"ModifiedPark\":  {\"model_key\":\"modifiedPark\", \"model_settings\": {\"useLargeWindFarmModel\": True, \"largeWindFarmCorrectionParameters\": lwf_paramters}},\n",
    "               \"TurbOPark\": {\"model_key\":\"turbOPark\", \"model_settings\": {\"wakeExpansion\": 0.04}},\n",
    "               \"CFDML\": {\"model_key\":\"cfdml\", \"model_settings\":{\"gnnType\": \"Offshore\", \"gnnStabilityClass\": \"UnstableNeutral\"}}}\n",
    "blockage_models = {\"BEET\": {\"model_key\":\"beet\", \"model_settings\":{\"significantAtmosphericStability\": False,\n",
    "                                                                  \"inclusionOfNeighborsBufferZoneInMeters\": 1000.0,\n",
    "                                                                  \"blockageCorrectionApplicationMethod\": \"OnWindSpeed\"}},\n",
    "                   \"CFDML\": {\"model_key\":\"cfdml\", \"model_settings\":{\"cfdmlSettings\": {\"gnnType\": \"Offshore\", \"gnnStabilityClass\": \"UnstableNeutral\"}, \n",
    "                                                                    \"blockageCorrectionApplicationMethod\": \"OnWindSpeed\",\n",
    "                                                                    \"cfdmlBlockageWindSpeedDependency\": \"FromBlockageExtrapolationCurve\"}}}\n",
    "# the below functions wrap steps used more than once in later code-cells\n",
    "def switch_off_fpm_export(input_json):\n",
    "    # this function makes sure fpm export is switched off - to speed up API response time\n",
    "    for fpm in input_json[\"energyEfficienciesSettings\"][\"turbineFlowAndPerformanceMatrixOutputSettings\"].keys():\n",
    "        if fpm != \"localTurbineWindSpeedsOutputSettings\":\n",
    "            input_json[\"energyEfficienciesSettings\"][\"turbineFlowAndPerformanceMatrixOutputSettings\"][fpm] = False\n",
    "        else:\n",
    "            input_json[\"energyEfficienciesSettings\"][\"turbineFlowAndPerformanceMatrixOutputSettings\"][fpm] = None\n",
    "\n",
    "def set_model_settings(input_json):\n",
    "    # let's set the modeling options contained in the json\n",
    "    input_json[\"energyEfficienciesSettings\"][\"calculateEfficiencies\"] = CALCULATE_EFFICIENCIES\n",
    "    # pull the relevant default settings from the dicts predefined above\n",
    "    input_json[\"energyEfficienciesSettings\"][\"wakeModel\"][\"wakeModelType\"] = WAKE_MODEL_CHOICE\n",
    "    input_json[\"energyEfficienciesSettings\"][\"wakeModel\"][wake_models[WAKE_MODEL_CHOICE][\"model_key\"]] = wake_models[WAKE_MODEL_CHOICE][\"model_settings\"]\n",
    "    input_json[\"energyEfficienciesSettings\"][\"blockageModel\"][\"blockageModelType\"] = BLOCKAGE_MODEL_CHOICE\n",
    "    input_json[\"energyEfficienciesSettings\"][\"blockageModel\"][blockage_models[BLOCKAGE_MODEL_CHOICE][\"model_key\"]] = blockage_models[BLOCKAGE_MODEL_CHOICE][\"model_settings\"]\n",
    "    switch_off_fpm_export(input_json)\n",
    "\n",
    "def submit_the_job(input_json_path, job_id_dict):\n",
    "    # load the json inputs \n",
    "    with open(input_json_path) as f:\n",
    "        json_string = f.read()\n",
    "        input_json = json.loads(json_string)\n",
    "    # override the modeling settings pre-exisitng in the json with the ones specified above\n",
    "    set_model_settings(input_json)\n",
    "    # save the updated json\n",
    "    with open(input_json_path, 'w') as f:\n",
    "        f.write(json.dumps(input_json, indent=4))\n",
    "    start = time.time()\n",
    "    response = requests.post(\n",
    "        api_url + 'AnnualEnergyProductionAsync', \n",
    "        headers=headers,\n",
    "        json = input_json\n",
    "    )\n",
    "    print(f'Response {response.status_code} - {response.reason} in {time.time() - start:.2f}s')\n",
    "    response_json = json.loads(response.content)\n",
    "    if response.status_code == 202:\n",
    "        job_id_dict[os.path.basename(input_json_path)] = response_json['jobId']\n",
    "        print(\"job ID: \" + str(response_json['jobId']))\n",
    "    return job_id_dict\n",
    "\n",
    "def poll_results(job_id_dict):\n",
    "    if not os.path.exists(f'./Results/'):\n",
    "        os.mkdir(f'./Results/')\n",
    "    jobs_completed_dict = {k:False for k in job_id_dict.keys()}\n",
    "    jobs_failed_list = []\n",
    "    while not all(jobs_completed_dict.values()):\n",
    "        for job_filename, job_id in job_id_dict.items():\n",
    "            if not jobs_completed_dict[job_filename]:\n",
    "                response = requests.get(api_url + 'AnnualEnergyProductionAsync', headers = headers, params={'jobId':job_id})\n",
    "                response_json = json.loads(response.content)\n",
    "                if response_json['status'] == 'SUCCESS':\n",
    "                    jobs_completed_dict[job_filename] = True\n",
    "                    print(f'Job {job_filename} is completed')\n",
    "                    with open(f'./Results/{job_filename}', 'w') as f:\n",
    "                        f.write(json.dumps(response_json, indent=4))\n",
    "                elif response_json['status'] == 'FAILED':\n",
    "                    print(f'Job {job_id} has FAILED.')\n",
    "                    jobs_failed_list.append(job_filename)\n",
    "                    jobs_completed_dict[job_filename] = True\n",
    "                else:\n",
    "                    print(f'Job {job_filename} is {response_json[\"status\"]}, JobID = {job_id}')\n",
    "        print(\"No. of completed jobs: \" + str(sum(jobs_completed_dict.values())) + \" out of \" + str(len(jobs_completed_dict)))\n",
    "        print(\"Among the completed jobs {} failed.\".format(len(jobs_failed_list)))\n",
    "        time.sleep(5)\n",
    "    return jobs_completed_dict, jobs_failed_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submit the batch of all simulation cases to the async endpoint of the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the jobs\n",
    "job_id_dict = {}\n",
    "for input_file in os.listdir(PATH_TO_INPUTS):\n",
    "    job_id_dict = submit_the_job(os.path.join(PATH_TO_INPUTS,input_file),job_id_dict)\n",
    "\n",
    "# persist the job_ids to disc\n",
    "with open('job_id_dict.json', 'w') as f:\n",
    "    f.write(json.dumps(job_id_dict, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At this point you can go get a coffee or lunch, or even switch the PC off. \n",
    "\n",
    "WindFarmerServices API will compute and store your results for 7 days. The subsequent cells read the job id's from file so execution of the notebook may be resumed at any point in time.\n",
    "\n",
    "Poll the API to see if all results are available..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the job ids submitted\n",
    "with open('job_id_dict.json', 'r') as f:\n",
    "    job_id_dict = json.load(f)\n",
    "# poll the API for results, until all jobs are completed\n",
    "jobs_completed_dict, jobs_failed_list = poll_results(job_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case some jobs failed (this may happen and not necessarily be linked with your inputs), let's re-submit jobs that did fail..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(jobs_failed_list) == 0:\n",
    "    print(\"All jobs completed successfully, nothing to re-submit.\")\n",
    "# re-submit failed jobs once\n",
    "resubmitted_job_id_dict = {}\n",
    "for job_file in jobs_failed_list:\n",
    "    print(f'Resubmitting job {job_file}')\n",
    "    resubmitted_job_id_dict = submit_the_job(os.path.join(PATH_TO_INPUTS,job_file), resubmitted_job_id_dict)\n",
    "# persist the job_ids to disc\n",
    "with open('resubmitted_job_id_dict.json', 'w') as f:\n",
    "    f.write(json.dumps(resubmitted_job_id_dict, indent=4))\n",
    "# and you can go get coffee again if needed...   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and poll for the re-submitted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(jobs_failed_list) == 0:\n",
    "    print(\"No jobs re-submitted, so nothing to poll for.\")\n",
    "# load the job ids submitted\n",
    "with open('resubmitted_job_id_dict.json', 'r') as f:\n",
    "    resubmitted_job_id_dict = json.load(f)\n",
    "# poll the API for results, until all jobs are completed\n",
    "jobs_completed_dict, jobs_failed_list = poll_results(resubmitted_job_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 3** Process the resulting jsons and extract the relevant numbers into a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_summary=[]\n",
    "for results_file in os.listdir('./Results'):\n",
    "    with open('./Results/'+results_file) as f:\n",
    "        json_string = f.read()\n",
    "        results_json = json.loads(json_string)\n",
    "    subject_farm_results_dict = results_json[\"results\"][\"windFarmAepOutputs\"][0]\n",
    "    if CALCULATE_EFFICIENCIES:\n",
    "        case_summary.append({\n",
    "            \"Case name\": results_file,\n",
    "            \"Gross Yield [MWh/Annum]\": subject_farm_results_dict[\"grossAnnualEnergyYield_MWh_per_year\"],\n",
    "            \"Blockage efficiency [%]\": subject_farm_results_dict[\"blockageOnAnnualEnergyYield_MWh_per_year\"] / subject_farm_results_dict[\"grossAnnualEnergyYield_MWh_per_year\"],\n",
    "            \"Internal wake efficiency [%]\": subject_farm_results_dict[\"internalWakesOnAnnualEnergyYield_MWh_per_year\"] / subject_farm_results_dict[\"blockageOnAnnualEnergyYield_MWh_per_year\"],\n",
    "            \"Hysteresis efficiency [%]\": subject_farm_results_dict[\"hysteresisAdjustmentOnAnnualEnergyYield_MWh_per_year\"] / subject_farm_results_dict[\"internalWakesOnAnnualEnergyYield_MWh_per_year\"],\n",
    "            \"Internal LWF efficiency [%]\": subject_farm_results_dict[\"largeWindFarmCorrectionOnAnnualEnergyYield_MWh_per_year\"] / subject_farm_results_dict[\"hysteresisAdjustmentOnAnnualEnergyYield_MWh_per_year\"],\n",
    "            \"External wake efficiency [%]\": subject_farm_results_dict[\"neighborsWakesOnAnnualEnergyYield_MWh_per_year\"] / subject_farm_results_dict[\"largeWindFarmCorrectionOnAnnualEnergyYield_MWh_per_year\"],\n",
    "            \"Full Yield [MWh/Annum]\": subject_farm_results_dict[\"fullAnnualEnergyYield_MWh_per_year\"],\n",
    "        })\n",
    "    else:\n",
    "        case_summary.append({\n",
    "            \"Case name\": results_file,\n",
    "            \"Gross Yield [MWh/Annum]\": subject_farm_results_dict[\"grossAnnualEnergyYield_MWh_per_year\"],\n",
    "            \"Full Yield [MWh/Annum]\": subject_farm_results_dict[\"fullAnnualEnergyYield_MWh_per_year\"],\n",
    "        })\n",
    "case_summary_df = pd.DataFrame.from_dict(case_summary)\n",
    "case_summary_df.sort_values(by='Full Yield [MWh/Annum]', ascending=True, inplace=True)\n",
    "case_summary_df['Yield uplift relative to worst choice [%]'] = round(case_summary_df['Full Yield [MWh/Annum]'] / case_summary_df['Full Yield [MWh/Annum]'].min() * 100 - 100,3)\n",
    "case_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best choice -> remove turbines: \" + case_summary_df.iloc[-1]['Case name'].replace('.json','').replace('_',','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read further values from the results can be determined from the API documentation, or look at the JSON files in your results folder.\n",
    "\n",
    "https://myworkspace.dnv.com/download/public/renewables/windfarmer/manuals/latest/WebAPI/ReleaseNotes/releaseNotes.html#openapi-specifications "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfdml_api_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
